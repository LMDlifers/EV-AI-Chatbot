{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #2563eb; color: white; padding: 20px; border-radius: 8px; margin: 10px 0; max-width: 1120px; box-shadow: 0 2px 4px rgba(0,0,0,0.1);\">\n",
    "\n",
    "## Dataset Overview: Electric Vehicle Charging Stations (2024)\n",
    "\n",
    "To power our AI chatbot, we are sourcing our knowledge from the **Electric Vehicle Charging Stations (2024)** dataset. This modern dataset is ideal for our mockup as it provides the essential data points needed to answer specific user queries. \n",
    "\n",
    "### Key Features:\n",
    "- **Rich location information** like Latitude and Longitude for proximity searches\n",
    "- **EV Connector Types** and **EV Network data** for filtering compatible and preferred charging options\n",
    "- Comprehensive coverage of charging stations across the network\n",
    "\n",
    "We will load this data into a **pandas DataFrame**, which will serve as the core \"database\" for all bot-driven station lookups.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installations and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "import kagglehub\n",
    "from kagglehub import KaggleDatasetAdapter\n",
    "from typing import List, Dict, Optional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetching Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EVChargingStationBot:\n",
    "    \"\"\"\n",
    "    AI Chatbot for Electric Vehicle Charging Station queries.\n",
    "    Supports semantic search, geographic clustering, structured filtering, and natural language responses.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, dataset_handle: str = \"sahirmaharajj/electric-vehicle-charging-stations-2024\", \n",
    "                file_path: str = None, embedding_model: str = 'all-MiniLM-L6-v2',\n",
    "                decoder_model: str = \"gpt2\", use_decoder: bool = True):\n",
    "        \"\"\"\n",
    "        Initialize the EV Charging Station Bot.\n",
    "        \n",
    "        Args:\n",
    "            dataset_handle: Kaggle dataset identifier\n",
    "            file_path: Specific file to load from dataset\n",
    "            embedding_model: SentenceTransformer model for semantic search\n",
    "            decoder_model: Decoder model for natural language generation\n",
    "            use_decoder: Whether to initialize decoder model (set False for faster startup)\n",
    "        \"\"\"\n",
    "        self.dataset_handle = dataset_handle\n",
    "        self.file_path = file_path\n",
    "        self.embedding_model_name = embedding_model\n",
    "        self.decoder_model_name = decoder_model\n",
    "        self.use_decoder = use_decoder\n",
    "        \n",
    "        # Core data structures\n",
    "        self.df = None\n",
    "        self.model = None\n",
    "        self.station_embeddings = None\n",
    "        self.geo_clusters = None\n",
    "        \n",
    "        # Decoder components\n",
    "        self.tokenizer = None\n",
    "        self.decoder_model = None\n",
    "        \n",
    "        # Initialize the bot\n",
    "        self._load_data()\n",
    "        self._preprocess_data()\n",
    "        self._initialize_embeddings()\n",
    "        if self.use_decoder:\n",
    "            self._initialize_decoder()\n",
    "        \n",
    "    def _load_data(self) -> None:\n",
    "        \"\"\"Load the EV charging station dataset.\"\"\"\n",
    "        try:\n",
    "            if self.file_path:\n",
    "                self.df = kagglehub.dataset_load(\n",
    "                    KaggleDatasetAdapter.PANDAS,\n",
    "                    self.dataset_handle,\n",
    "                    self.file_path\n",
    "                )\n",
    "            else:\n",
    "                # Download and explore dataset first\n",
    "                path = kagglehub.dataset_download(self.dataset_handle)\n",
    "                print(f\"Dataset downloaded to: {path}\")\n",
    "                # User needs to specify the correct file_path\n",
    "                raise ValueError(\"Please specify the file_path after exploring the dataset\")\n",
    "                \n",
    "            print(f\"Loaded {len(self.df)} charging stations\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading data: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def _preprocess_data(self) -> None:\n",
    "        \"\"\"Preprocess the dataset for optimal searching.\"\"\"\n",
    "        # Clean and standardize columns FIRST\n",
    "        self._clean_data()\n",
    "        \n",
    "        # Extract coordinates from georeferenced column\n",
    "        if 'New Georeferenced Column' in self.df.columns:\n",
    "            coordinates = self.df['New Georeferenced Column'].str.extract(r'POINT \\(([^)]+)\\)')\n",
    "            coord_split = coordinates[0].str.split(' ', expand=True)\n",
    "            if len(coord_split.columns) >= 2:\n",
    "                self.df['longitude'] = pd.to_numeric(coord_split[0], errors='coerce')\n",
    "                self.df['latitude'] = pd.to_numeric(coord_split[1], errors='coerce')\n",
    "        \n",
    "        # Create rich descriptions for semantic search (after cleaning)\n",
    "        self.df['description'] = self.df.apply(self._create_station_description, axis=1)\n",
    "        \n",
    "        print(\"Data preprocessing completed\")\n",
    "    \n",
    "    def _create_station_description(self, row) -> str:\n",
    "        \"\"\"Create a rich text description for each charging station.\"\"\"\n",
    "        description_parts = []\n",
    "        \n",
    "        if pd.notna(row.get('Station Name')):\n",
    "            description_parts.append(f\"Station: {row['Station Name']}\")\n",
    "        \n",
    "        if pd.notna(row.get('City')) and pd.notna(row.get('Street Address')):\n",
    "            description_parts.append(f\"Located in {row['City']} at {row['Street Address']}\")\n",
    "        \n",
    "        if pd.notna(row.get('Access Days Time')):\n",
    "            description_parts.append(f\"Hours: {row['Access Days Time']}\")\n",
    "        \n",
    "        # Charging capabilities\n",
    "        charging_info = []\n",
    "        if pd.notna(row.get('EV Level1 EVSE Num')) and row['EV Level1 EVSE Num'] > 0:\n",
    "            charging_info.append(f\"Level 1: {row['EV Level1 EVSE Num']} ports\")\n",
    "        if pd.notna(row.get('EV Level2 EVSE Num')) and row['EV Level2 EVSE Num'] > 0:\n",
    "            charging_info.append(f\"Level 2: {row['EV Level2 EVSE Num']} ports\")\n",
    "        if pd.notna(row.get('EV DC Fast Count')) and row['EV DC Fast Count'] > 0:\n",
    "            charging_info.append(f\"DC Fast: {row['EV DC Fast Count']} ports\")\n",
    "        \n",
    "        if charging_info:\n",
    "            description_parts.append(\"Charging: \" + \", \".join(charging_info))\n",
    "        \n",
    "        return \". \".join(description_parts)\n",
    "    \n",
    "    def _clean_data(self) -> None:\n",
    "        \"\"\"Clean and standardize the dataset.\"\"\"\n",
    "        # Convert numeric columns - handle \"NONE\" strings\n",
    "        numeric_cols = ['EV Level1 EVSE Num', 'EV Level2 EVSE Num', 'EV DC Fast Count']\n",
    "        for col in numeric_cols:\n",
    "            if col in self.df.columns:\n",
    "                # Replace \"NONE\" with 0, then convert to numeric\n",
    "                self.df[col] = self.df[col].astype(str).str.replace('NONE', '0')\n",
    "                self.df[col] = pd.to_numeric(self.df[col], errors='coerce').fillna(0).astype(int)\n",
    "        \n",
    "        # Clean string columns\n",
    "        string_cols = ['Station Name', 'City', 'Street Address']\n",
    "        for col in string_cols:\n",
    "            if col in self.df.columns:\n",
    "                self.df[col] = self.df[col].astype(str).str.strip()\n",
    "    \n",
    "    def _initialize_embeddings(self) -> None:\n",
    "        \"\"\"Initialize the sentence transformer model and create embeddings.\"\"\"\n",
    "        try:\n",
    "            self.model = SentenceTransformer(self.embedding_model_name)\n",
    "            self.station_embeddings = self.model.encode(self.df['description'].tolist())\n",
    "            print(\"Embeddings initialized successfully\")\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Could not initialize embeddings: {e}\")\n",
    "            self.model = None\n",
    "            self.station_embeddings = None\n",
    "    \n",
    "    def _initialize_decoder(self) -> None:\n",
    "        \"\"\"Initialize the decoder model for natural language generation.\"\"\"\n",
    "        try:\n",
    "            self.tokenizer = AutoTokenizer.from_pretrained(self.decoder_model_name)\n",
    "            self.decoder_model = AutoModelForCausalLM.from_pretrained(self.decoder_model_name)\n",
    "            \n",
    "            # Set pad token if not present\n",
    "            if self.tokenizer.pad_token is None:\n",
    "                self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "            \n",
    "            print(\"Decoder model initialized for response generation\")\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Could not initialize decoder: {e}\")\n",
    "            self.tokenizer = None\n",
    "            self.decoder_model = None\n",
    "    \n",
    "    def setup_geographic_clustering(self, n_clusters: int = 20) -> None:\n",
    "        \"\"\"Setup geographic clustering for location-based optimization.\"\"\"\n",
    "        if 'latitude' in self.df.columns and 'longitude' in self.df.columns:\n",
    "            # Remove rows with missing coordinates\n",
    "            valid_coords = self.df.dropna(subset=['latitude', 'longitude'])\n",
    "            \n",
    "            if len(valid_coords) > 0:\n",
    "                kmeans = KMeans(n_clusters=min(n_clusters, len(valid_coords)), random_state=42)\n",
    "                coords = valid_coords[['latitude', 'longitude']].values\n",
    "                cluster_labels = kmeans.fit_predict(coords)\n",
    "                \n",
    "                # Map clusters back to original dataframe\n",
    "                self.df['geo_cluster'] = -1  # Default for missing coordinates\n",
    "                self.df.loc[valid_coords.index, 'geo_cluster'] = cluster_labels\n",
    "                \n",
    "                self.geo_clusters = kmeans\n",
    "                print(f\"Geographic clustering completed with {n_clusters} clusters\")\n",
    "            else:\n",
    "                print(\"No valid coordinates found for clustering\")\n",
    "        else:\n",
    "            print(\"Latitude/Longitude columns not available for clustering\")\n",
    "    \n",
    "    # === BASIC SEARCH METHODS ===\n",
    "    def find_by_city(self, city: str, limit: int = 10) -> pd.DataFrame:\n",
    "        \"\"\"Find charging stations by city name.\"\"\"\n",
    "        mask = self.df['City'].str.contains(city, case=False, na=False)\n",
    "        return self.df[mask].head(limit)\n",
    "    \n",
    "    def find_fast_charging(self, city: str = None, limit: int = 10) -> pd.DataFrame:\n",
    "        \"\"\"Find stations with DC fast charging.\"\"\"\n",
    "        # Convert to numeric on the fly if needed\n",
    "        dc_fast_col = pd.to_numeric(self.df['EV DC Fast Count'], errors='coerce').fillna(0)\n",
    "        mask = dc_fast_col > 0\n",
    "        \n",
    "        if city:\n",
    "            city_mask = self.df['City'].str.contains(city, case=False, na=False)\n",
    "            mask = mask & city_mask\n",
    "        \n",
    "        return self.df[mask].head(limit)\n",
    "\n",
    "    def find_level2_charging(self, city: str = None, min_ports: int = 1, limit: int = 10) -> pd.DataFrame:\n",
    "        \"\"\"Find stations with Level 2 charging.\"\"\"\n",
    "        # Convert to numeric on the fly if needed\n",
    "        level2_col = pd.to_numeric(self.df['EV Level2 EVSE Num'], errors='coerce').fillna(0)\n",
    "        mask = level2_col >= min_ports\n",
    "        \n",
    "        if city:\n",
    "            city_mask = self.df['City'].str.contains(city, case=False, na=False)\n",
    "            mask = mask & city_mask\n",
    "        \n",
    "        return self.df[mask].head(limit)\n",
    "    \n",
    "    def find_24_hour_stations(self, city: str = None, limit: int = 10) -> pd.DataFrame:\n",
    "        \"\"\"Find 24-hour accessible charging stations.\"\"\"\n",
    "        mask = self.df['Access Days Time'].str.contains('24 hours', case=False, na=False)\n",
    "        \n",
    "        if city:\n",
    "            city_mask = self.df['City'].str.contains(city, case=False, na=False)\n",
    "            mask = mask & city_mask\n",
    "        \n",
    "        return self.df[mask].head(limit)\n",
    "    \n",
    "    def find_nearby_stations(self, lat: float, lon: float, radius_km: float = 10, limit: int = 10) -> pd.DataFrame:\n",
    "        \"\"\"Find charging stations within a radius of given coordinates.\"\"\"\n",
    "        if 'latitude' not in self.df.columns or 'longitude' not in self.df.columns:\n",
    "            raise ValueError(\"Coordinate data not available\")\n",
    "        \n",
    "        # Calculate distances using Haversine formula\n",
    "        distances = self._calculate_distances(lat, lon)\n",
    "        nearby_mask = distances <= radius_km\n",
    "        \n",
    "        # Sort by distance\n",
    "        nearby_stations = self.df[nearby_mask].copy()\n",
    "        nearby_stations['distance_km'] = distances[nearby_mask]\n",
    "        \n",
    "        return nearby_stations.sort_values('distance_km').head(limit)\n",
    "    \n",
    "    def semantic_search(self, query: str, limit: int = 5) -> pd.DataFrame:\n",
    "        \"\"\"Perform semantic search using embeddings.\"\"\"\n",
    "        if self.model is None or self.station_embeddings is None:\n",
    "            raise ValueError(\"Embeddings not available. Initialize embeddings first.\")\n",
    "        \n",
    "        # Encode the query\n",
    "        query_embedding = self.model.encode([query])\n",
    "        \n",
    "        # Calculate similarities\n",
    "        similarities = cosine_similarity(query_embedding, self.station_embeddings)[0]\n",
    "        \n",
    "        # Get top results\n",
    "        top_indices = np.argsort(similarities)[::-1][:limit]\n",
    "        results = self.df.iloc[top_indices].copy()\n",
    "        results['similarity_score'] = similarities[top_indices]\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    # === CHAT METHODS WITH NATURAL LANGUAGE RESPONSES ===\n",
    "    \n",
    "    def chat_semantic_search(self, query: str, limit: int = 3) -> str:\n",
    "        \"\"\"\n",
    "        Perform semantic search and generate a natural language response.\n",
    "        \"\"\"\n",
    "        # Get search results\n",
    "        results_df = self.semantic_search(query, limit)\n",
    "        \n",
    "        # Generate natural language response\n",
    "        if self.use_decoder and self.decoder_model is not None:\n",
    "            response = self._generate_response(query, results_df, search_type=\"semantic\")\n",
    "        else:\n",
    "            response = self._simple_template_decoder(query, results_df, search_type=\"semantic\")\n",
    "        \n",
    "        return response\n",
    "    \n",
    "    def chat_find_nearby(self, lat: float, lon: float, radius_km: float = 10, limit: int = 3) -> str:\n",
    "        \"\"\"\n",
    "        Find nearby stations and generate directions/response.\n",
    "        \"\"\"\n",
    "        results_df = self.find_nearby_stations(lat, lon, radius_km, limit)\n",
    "        \n",
    "        # Create location context\n",
    "        location_query = f\"charging stations near coordinates {lat}, {lon} within {radius_km}km\"\n",
    "        \n",
    "        if self.use_decoder and self.decoder_model is not None:\n",
    "            response = self._generate_response(location_query, results_df, search_type=\"location\")\n",
    "        else:\n",
    "            response = self._simple_template_decoder(location_query, results_df, search_type=\"location\")\n",
    "        \n",
    "        return response\n",
    "    \n",
    "    def chat_find_fast_charging(self, city: str = None, limit: int = 3) -> str:\n",
    "        \"\"\"\n",
    "        Find fast charging stations with natural language response.\n",
    "        \"\"\"\n",
    "        results_df = self.find_fast_charging(city, limit)\n",
    "        \n",
    "        city_text = f\"in {city}\" if city else \"\"\n",
    "        query = f\"fast charging stations {city_text}\"\n",
    "        \n",
    "        if self.use_decoder and self.decoder_model is not None:\n",
    "            response = self._generate_response(query, results_df, search_type=\"fast_charging\")\n",
    "        else:\n",
    "            response = self._simple_template_decoder(query, results_df, search_type=\"fast_charging\")\n",
    "        \n",
    "        return response\n",
    "    \n",
    "    def chat_find_level2_charging(self, city: str = None, min_ports: int = 1, limit: int = 3) -> str:\n",
    "        \"\"\"\n",
    "        Find Level 2 charging stations with natural language response.\n",
    "        \"\"\"\n",
    "        results_df = self.find_level2_charging(city, min_ports, limit)\n",
    "        \n",
    "        city_text = f\"in {city}\" if city else \"\"\n",
    "        query = f\"Level 2 charging stations {city_text}\"\n",
    "        \n",
    "        if self.use_decoder and self.decoder_model is not None:\n",
    "            response = self._generate_response(query, results_df, search_type=\"level2_charging\")\n",
    "        else:\n",
    "            response = self._simple_template_decoder(query, results_df, search_type=\"level2_charging\")\n",
    "        \n",
    "        return response\n",
    "    \n",
    "    # === RESPONSE GENERATION METHODS ===\n",
    "    \n",
    "    def _generate_response(self, query: str, results_df: pd.DataFrame, search_type: str) -> str:\n",
    "        \"\"\"\n",
    "        Generate natural language response using decoder model.\n",
    "        \"\"\"\n",
    "        # Prepare context from search results\n",
    "        context = self._prepare_context(results_df, search_type)\n",
    "        \n",
    "        # Create prompt for the decoder\n",
    "        prompt = self._create_prompt(query, context, search_type)\n",
    "        \n",
    "        # Generate response using decoder\n",
    "        response = self._decode_response(prompt)\n",
    "        \n",
    "        return response\n",
    "    \n",
    "    def _prepare_context(self, results_df: pd.DataFrame, search_type: str) -> str:\n",
    "        \"\"\"\n",
    "        Prepare structured context from search results.\n",
    "        \"\"\"\n",
    "        if results_df.empty:\n",
    "            return \"No stations found matching your criteria.\"\n",
    "        \n",
    "        context_parts = []\n",
    "        context_parts.append(f\"Found {len(results_df)} charging stations:\")\n",
    "        \n",
    "        for idx, row in results_df.iterrows():\n",
    "            station_info = []\n",
    "            station_info.append(f\"- {row['Station Name']}\")\n",
    "            station_info.append(f\"Address: {row['Street Address']}, {row['City']}\")\n",
    "            station_info.append(f\"Hours: {row['Access Days Time']}\")\n",
    "            \n",
    "            # Add charging details\n",
    "            charging_details = []\n",
    "            if row['EV Level2 EVSE Num'] > 0:\n",
    "                charging_details.append(f\"Level 2: {row['EV Level2 EVSE Num']} ports\")\n",
    "            if row['EV DC Fast Count'] > 0:\n",
    "                charging_details.append(f\"DC Fast: {row['EV DC Fast Count']} ports\")\n",
    "            \n",
    "            if charging_details:\n",
    "                station_info.append(f\"Charging: {', '.join(charging_details)}\")\n",
    "            \n",
    "            # Add distance if available\n",
    "            if 'distance_km' in row:\n",
    "                station_info.append(f\"Distance: {row['distance_km']:.1f} km\")\n",
    "            \n",
    "            context_parts.append(\" | \".join(station_info))\n",
    "        \n",
    "        return \"\\n\".join(context_parts)\n",
    "    \n",
    "    def _create_prompt(self, query: str, context: str, search_type: str) -> str:\n",
    "        \"\"\"\n",
    "        Create a structured prompt for the decoder model.\n",
    "        \"\"\"\n",
    "\n",
    "        prompt_templates = {\n",
    "            \"semantic\": \n",
    "            \n",
    "                f\"\"\"User asked: \"{query}\"\n",
    "\n",
    "                Here are the relevant charging stations I found:\n",
    "                {context}\n",
    "\n",
    "                Please provide a helpful response with directions and recommendations:\"\"\",\n",
    "                        \n",
    "            \"location\": \n",
    "\n",
    "                f\"\"\"User is looking for: {query}\n",
    "\n",
    "                Here are the nearby charging stations:\n",
    "                {context}\n",
    "\n",
    "                Please provide directions and recommendations:\"\"\",\n",
    "                        \n",
    "            \"fast_charging\": \n",
    "\n",
    "                f\"\"\"User is looking for: {query}\n",
    "\n",
    "                Here are the available fast charging options:\n",
    "                {context}\n",
    "\n",
    "                Please provide helpful information and directions:\"\"\",\n",
    "                        \n",
    "            \"level2_charging\": \n",
    "\n",
    "                f\"\"\"User is looking for: {query}\n",
    "\n",
    "                Here are the available Level 2 charging options:\n",
    "                {context}\n",
    "\n",
    "                Please provide helpful information and recommendations:\"\"\"\n",
    "        }\n",
    "                \n",
    "        return prompt_templates.get(search_type, prompt_templates[\"semantic\"])\n",
    "    \n",
    "    def _decode_response(self, prompt: str, max_length: int = 200, temperature: float = 0.7) -> str:\n",
    "        \"\"\"\n",
    "        Generate response using the decoder model.\n",
    "        \"\"\"\n",
    "        # Encode the prompt\n",
    "        inputs = self.tokenizer.encode(prompt, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "        \n",
    "        # Generate response using different decoding strategies\n",
    "        with torch.no_grad():\n",
    "            outputs = self.decoder_model.generate(\n",
    "                inputs,\n",
    "                max_length=inputs.shape[1] + max_length,\n",
    "                temperature=temperature,\n",
    "                do_sample=True,\n",
    "                top_p=0.9,\n",
    "                top_k=50,\n",
    "                pad_token_id=self.tokenizer.eos_token_id,\n",
    "                num_return_sequences=1\n",
    "            )\n",
    "        \n",
    "        # Decode and clean the response\n",
    "        generated_text = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        \n",
    "        # Extract only the generated part (remove the prompt)\n",
    "        response = generated_text[len(prompt):].strip()\n",
    "        \n",
    "        return response if response else \"I found the stations listed above. Please let me know if you need more specific directions!\"\n",
    "    \n",
    "    def _simple_template_decoder(self, query: str, results_df: pd.DataFrame, search_type: str) -> str:\n",
    "        \"\"\"\n",
    "        Template-based response generation (lighter alternative).\n",
    "        \"\"\"\n",
    "        if results_df.empty:\n",
    "            return f\"I couldn't find any charging stations matching '{query}'. Try broadening your search criteria.\"\n",
    "        \n",
    "        station_count = len(results_df)\n",
    "        first_station = results_df.iloc[0]\n",
    "        \n",
    "        responses = {\n",
    "            \"semantic\": f\"I found {station_count} stations matching '{query}'. The top result is {first_station['Station Name']} located at {first_station['Street Address']}, {first_station['City']}. They're open {first_station['Access Days Time']}. Would you like directions or more details about any of these stations?\",\n",
    "            \n",
    "            \"location\": f\"There are {station_count} charging stations within your specified area. The closest is {first_station['Station Name']} at {first_station['Street Address']}, {first_station['City']}. You can charge there during {first_station['Access Days Time']}. Shall I provide turn-by-turn directions?\",\n",
    "            \n",
    "            \"fast_charging\": f\"Great! I found {station_count} fast charging stations. {first_station['Station Name']} in {first_station['City']} has {first_station['EV DC Fast Count']} DC fast charging ports and is available {first_station['Access Days Time']}. This will get you charged up quickly!\",\n",
    "            \n",
    "            \"level2_charging\": f\"I found {station_count} Level 2 charging stations. {first_station['Station Name']} in {first_station['City']} has {first_station['EV Level2 EVSE Num']} Level 2 ports and is available {first_station['Access Days Time']}. Perfect for longer charging sessions!\"\n",
    "        }\n",
    "        \n",
    "        return responses.get(search_type, responses[\"semantic\"])\n",
    "    \n",
    "    # === UTILITY METHODS ===\n",
    "    \n",
    "    def _calculate_distances(self, lat: float, lon: float) -> np.ndarray:\n",
    "        \"\"\"Calculate distances using Haversine formula.\"\"\"\n",
    "        R = 6371  # Earth's radius in kilometers\n",
    "        \n",
    "        lat_rad = np.radians(lat)\n",
    "        lon_rad = np.radians(lon)\n",
    "        \n",
    "        station_lats = np.radians(self.df['latitude'].fillna(0))\n",
    "        station_lons = np.radians(self.df['longitude'].fillna(0))\n",
    "        \n",
    "        dlat = station_lats - lat_rad\n",
    "        dlon = station_lons - lon_rad\n",
    "        \n",
    "        a = np.sin(dlat/2)**2 + np.cos(lat_rad) * np.cos(station_lats) * np.sin(dlon/2)**2\n",
    "        c = 2 * np.arcsin(np.sqrt(a))\n",
    "        \n",
    "        return R * c\n",
    "    \n",
    "    def get_station_details(self, station_id: int) -> Dict:\n",
    "        \"\"\"Get detailed information about a specific station.\"\"\"\n",
    "        station = self.df.iloc[station_id]\n",
    "        return station.to_dict()\n",
    "    \n",
    "    def get_cities(self) -> List[str]:\n",
    "        \"\"\"Get list of all cities with charging stations.\"\"\"\n",
    "        return sorted(self.df['City'].unique())\n",
    "    \n",
    "    def get_summary_stats(self) -> Dict:\n",
    "        \"\"\"Get summary statistics about the dataset.\"\"\"\n",
    "        return {\n",
    "            'total_stations': len(self.df),\n",
    "            'cities': len(self.df['City'].unique()),\n",
    "            'level1_stations': (self.df['EV Level1 EVSE Num'] > 0).sum(),\n",
    "            'level2_stations': (self.df['EV Level2 EVSE Num'] > 0).sum(),\n",
    "            'fast_dc_stations': (self.df['EV DC Fast Count'] > 0).sum(),\n",
    "            'total_level2_ports': self.df['EV Level2 EVSE Num'].sum(),\n",
    "            'total_fast_dc_ports': self.df['EV DC Fast Count'].sum()\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/sahirmaharajj/electric-vehicle-charging-stations-2024?dataset_version_number=2&file_name=Electric_Vehicle_Charging_Stations.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48.2k/48.2k [00:00<00:00, 9.32MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 385 charging stations\n",
      "Data preprocessing completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings initialized successfully\n",
      "Decoder model initialized for response generation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¤– Bot: - The Tesla Supercharger is only available for charging on Friday, and is located in the Westfield Shopping Center. Please refer to the FAQ below to find out if it is available at all.\n",
      "\n",
      "\n",
      "- The Tesla Supercharger is available only to drivers who have a valid Tesla permit, and must be registered in the Westfield Shopping Center. Please see the \"How to Register\" section of the FAQ for more information.\n",
      "\n",
      "- The Tesla Supercharger is only available for charging on Saturday, and is located at the Westfield Shopping Center. Please refer to the \"How to Register\" section of the FAQ for more information.\n",
      "\n",
      "\n",
      "- The Tesla Supercharger is only available for charging on Sunday, and is located at the Westfield Shopping Center. Please refer to the \"How to Register\" section of the FAQ for more information.\n",
      "\n",
      "- The Tesla Supercharger is only available for charging on Monday, and is located at the Westfield Shopping Center\n",
      "ðŸ¤– Bot: 1.        Please provide directions and recommendations:\n",
      "\n",
      "2.                          \n",
      "\n",
      "3.                                \n",
      "\n",
      "4.                               \n",
      "\n",
      "5.                                    \n",
      "\n",
      "6.\n",
      "ðŸ¤– Bot: The following stations are available:\n",
      "\n",
      "1. 7 Mile Circle\n",
      "\n",
      "2. 5 Mile Circle\n",
      "\n",
      "3. 10 Mile Circle\n",
      "\n",
      "4. 15 Mile Circle\n",
      "\n",
      "5. 25 Mile Circle\n",
      "\n",
      "6. 40 Mile Circle\n",
      "\n",
      "7. 50 Mile Circle\n",
      "\n",
      "8. 100 Mile Circle\n",
      "\n",
      "9. 500 Mile Circle\n",
      "\n",
      "10. 1,000 Mile Circle\n",
      "\n",
      "11. 1,500 Mile Circle\n",
      "\n",
      "12. 1,000 Mile Circle\n",
      "\n",
      "13. 1,500 Mile Circle\n",
      "\n",
      "14. 1,000 Mile Circle\n",
      "\n",
      "15. 1,500 Mile Circle\n",
      "\n",
      "16. 1,500 Mile Circle\n",
      "\n",
      "17. 1,500 Mile Circle\n",
      "\n",
      "18. 1,500 Mile Circle\n",
      "\n",
      "19. 1,500 Mile Circle\n",
      "\n",
      "20. 1,500 Mile Circle\n",
      "\n",
      "21. 1,500 Mile Circle\n",
      "\n",
      "22. 1,500 Mile Circle\n",
      "\n",
      "23.\n"
     ]
    }
   ],
   "source": [
    "# === USAGE EXAMPLES ===\n",
    "\n",
    "# Initialize with decoder (full AI capabilities)\n",
    "bot = EVChargingStationBot(\n",
    "    file_path=\"Electric_Vehicle_Charging_Stations.csv\",\n",
    "    decoder_model=\"gpt2\",  # or \"gpt2\", \"distilgpt2\" \n",
    "    use_decoder=True\n",
    ")\n",
    "\n",
    "# Initialize without decoder (faster startup, template responses)\n",
    "# bot = EVChargingStationBot(\n",
    "#     file_path=\"Electric_Vehicle_Charging_Stations.csv\",\n",
    "#     use_decoder=False\n",
    "# )\n",
    "\n",
    "# Natural language chat responses\n",
    "print(\"ðŸ¤– Bot:\", bot.chat_semantic_search(\"Tesla supercharger downtown\"))\n",
    "print(\"ðŸ¤– Bot:\", bot.chat_find_nearby(42.3601, -71.0589, radius_km=5))\n",
    "print(\"ðŸ¤– Bot:\", bot.chat_find_fast_charging(\"Boston\"))\n",
    "\n",
    "# # Traditional DataFrame results (still available)\n",
    "# results = bot.find_fast_charging(\"Boston\")\n",
    "# nearby = bot.find_nearby_stations(42.3601, -71.0589, radius_km=5)\n",
    "# semantic_results = bot.semantic_search(\"Tesla supercharger downtown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a decoder to return the results with a direction to it\n",
    "semantic_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
